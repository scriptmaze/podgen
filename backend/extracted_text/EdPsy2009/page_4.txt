11. Teacher-made assessment strategies
conversations, email, school district websites and parent-teachers conferences. Effective communication requires
that teachers can clearly explain the purpose and characteristics of the assessment as well as the meaning of
students' performance. This requires a thorough knowledge of the types and purposes of teacher made and
standardized assessments (this chapter and Chapter 12) and well as clear communication skills (Chapter 8).
We now consider each step in the process of assessment for learning in more detail. In order to be able to select
and administer appropriate assessment techniques teachers need to know about the variety of techniques that can
be used as well as what factors ensure that the assessment techniques are high quality. We begin by considering
high quality assessments.
Selecting appropriate assessment techniques I: high quality assessments
For an assessment to be high quality it needs to have good validity and reliability as well as absence from bias.
Validity
Validity is the evaluation of the "adequacy and appropriateness of the interpretations and uses of assessment
results" for a given group of individuals (Linn & Miller, 2005, p. 68). For example, is it appropriate to conclude that
the results of a mathematics test on fractions given to recent immigrants accurately represents their understanding
of fractions? Is it appropriate for the teacher to conclude, based on her observations, that a kindergarten student,
Jasmine, has Attention Deficit Disorder because she does not follow the teachers oral instructions? Obviously in
each situation other interpretations are possible that the immigrant students have poor English skills rather than
mathematics skills, or that Jasmine may be hearing impaired.
It is important to understand that validity refers to the interpretation and uses made of the results of an
assessment procedure not of the assessment procedure itself. For example, making judgments about the results of
the same test on fractions may be valid if the students all understand English well. A teacher concluding from her
observations that the kindergarten student has Attention Deficit Disorder (ADD) may be appropriate if the student
has been screened for hearing and other disorders (although the classification of a disorder like ADD cannot be
made by one teacher). Validity involves making an overall judgment of the degree to which the interpretations and
uses of the assessment results are justified. Validity is a matter of degree (e.g. high, moderate, or low validity)
rather than all-or none (e.g. totally valid VS invalid) (Linn & Miller, 2005).
Three sources of evidence are considered when assessing validity-content, construct and predictive. Content
validity evidence is associated with the question: How well does the assessment include the content or tasks it is
supposed to? For example, suppose your educational psychology instructor devises a mid-term test and tells you
this includes chapters one to seven in the text book. Obviously, all the items in test should be based on the content
from educational psychology, not your methods or cultural foundations classes. Also, the items in the test should
cover content from all seven chapters and not just chapters three to seven-unless the instructor tells you that these
chapters have priority.
Teachers' have to be clear about their purposes and priorities for instruction before they can begin to gather
evidence related content validity. Content validation determines the degree that assessment tasks are relevant and
representative of the tasks judged by the teacher (or test developer) to represent their goals and objectives (Linn &
Miller, 2005). It is important for teachers to think about content validation when devising assessment tasks and
one way to help do this is to devise a Table of Specifications. An example, based on Pennsylvania's State standards
243
